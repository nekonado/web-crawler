name: Scheduled Web Crawler with Dynamic GitHub Pages URL

on:
  schedule:
    # 日本時間で月曜日の午前3時（UTC日曜日18:00）
    - cron: "0 18 * * 0"
  workflow_dispatch: # 手動実行も可能にする

permissions:
  contents: write

jobs:
  crawl-and-deploy:
    runs-on: ubuntu-latest

    steps:
      # gh-pagesブランチの存在確認を削除し、mainブランチだけをチェックアウト
      - name: Checkout main branch
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Copy sample config if needed
        run: |
          if [ ! -f config.json ]; then
            cp config.sample.json config.json
          fi

      - name: Run crawler
        run: |
          mkdir -p output/actions
          OUTPUT_DIR=output/actions python crawler.py

      - name: Process crawler results
        id: process-results
        run: |
          # タイムスタンプ付きフォルダを見つける (最新のディレクトリを取得)
          LATEST_DIR=$(find output/actions -mindepth 1 -maxdepth 1 -type d | sort -r | head -1)

          if [ -n "${LATEST_DIR}" ]; then
            echo "latest_dir=${LATEST_DIR}" >> $GITHUB_OUTPUT
            echo "Latest directory: ${LATEST_DIR}"
          else
            echo "No timestamp directory found"
            exit 1
          fi

      - name: Prepare Pages deployment
        id: prepare-deployment
        run: |
          # GitHub Pagesのデプロイ用ディレクトリを作成
          mkdir -p pages_deploy

          # ランダムな文字列を生成して非公開URLパスとして使用
          RANDOM_PATH=$(openssl rand -hex 16)
          echo "random_path=${RANDOM_PATH}" >> $GITHUB_OUTPUT
          mkdir -p pages_deploy/${RANDOM_PATH}

          # 最新のCSVファイルをコピー
          cp output/actions/crawl_result_latest.csv pages_deploy/${RANDOM_PATH}/data.csv
          cp ${{ steps.process-results.outputs.latest_dir }}/crawl_result.csv pages_deploy/${RANDOM_PATH}/latest.csv

          # インデックスファイルを作成（常に同じURLでアクセス可能）
          # このJSONファイルはGASからアクセスされる
          echo "{\"current_path\":\"${RANDOM_PATH}\",\"updated_at\":\"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"}" > pages_deploy/index.json

          # HTMLテンプレートをGitHub Pagesディレクトリにコピー
          cp templates/index.html pages_deploy/index.html

      - name: Commit results to main branch
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # latest.csvファイルと結果フォルダのみをコミット
          git add output/actions/crawl_result_latest.csv
          git add ${{ steps.process-results.outputs.latest_dir }}/crawl_result.csv

          git commit -m "Update crawler results [skip ci]" || echo "No changes to commit"
          git push

      - name: Deploy to GitHub Pages
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          folder: pages_deploy
          branch: gh-pages
          target-folder: /
